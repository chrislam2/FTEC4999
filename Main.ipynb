{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Algorithms for Statistical Learning - Experiment Notebook #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 Environment Setup ##\n",
    "\n",
    "In this section, libraries, datasets and associative python programme are imported, as well as the setup of the experiment environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Packages and Libraries ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter\n",
    "!pip install numpy\n",
    "!pip install torch torchvision \n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torch_xla\n",
    "!pip install torch-neuron --extra-index-url=https://pip.repos.neuron.amazonaws.com/\n",
    "!pip install pytorch torchvision cudatoolkit=9.0 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import string\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import csv\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Python Programme**\n",
    "\n",
    "Here is the section for importing external python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Set up Experiment Environment ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize GPU**\n",
    "\n",
    "For local environments, please utilize the GPU to speed up the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utililze TPU**\n",
    "\n",
    "To shorten the training time, we highly recommend that experiments should be done in Google Colab. Enable the following code in the Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume that you are on the Google Colab platform.\n",
    "#!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "device = xm.xla_device()\n",
    "\n",
    "def to_device(data, device):\n",
    "    data.to(device)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.2 Datasets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.0 Preprocessing Functions ####\n",
    "Here are the functions for preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#       Normalization        #\n",
    "##############################\n",
    "def normalize_tensor(tensor):\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    normalized_tensor = (tensor - mean) / std\n",
    "    return normalized_tensor\n",
    "\n",
    "##############################\n",
    "#    Image Preprocessing     #\n",
    "##############################\n",
    "def load_image(filename):\n",
    "  im_pil = Image.open(filename)\n",
    "  im = np.array(im_pil).astype(np.float32) / 255\n",
    "  return im\n",
    "\n",
    "##############################\n",
    "# Text Dataset Preprocessing #\n",
    "##############################\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.1 Importing Datasets from Packages ####\n",
    "This will load the dataset automatically downloaded from the package. Remember the datasets will be stored in the folder \"Datasets\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Download Dataset\n",
    "MNIST_train_dataset = MNIST(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test_dataset = MNIST(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the dataset\n",
    "print(\"=== Raw Data Samples from the MNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_train_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Raw Data Samples from the MNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_test_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Download Dataset\n",
    "CIFAR10_train_dataset = CIFAR10(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "CIFAR10_test_dataset = CIFAR10(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the CIFAR10 train dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_train_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the raw data from the CIFAR10 test dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_test_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "# Download Dataset\n",
    "EMNIST_train_dataset = EMNIST(root='./Datasets', split='byclass', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "EMNIST_test_dataset = EMNIST(root='./Datasets', split='byclass', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = EMNIST_train_dataset\n",
    "test_dataset = EMNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"EMNIST\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the EMNIST train dataset\n",
    "print(\"=== Raw Data Samples from the EMNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = EMNIST_train_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the raw data from the EMNIST test dataset\n",
    "print(\"=== Raw Data Samples from the EMNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = EMNIST_test_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.2 Importing Datasets from Downloaded Files ####\n",
    "This will load the dataset downloaded in the local directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**\n",
    "\n",
    "The source of this dataset comes from https://www.kaggle.com/c/GiveMeSomeCredit\n",
    "\n",
    "Note: This dataset is borrowed from the datasets used in the competitive task in FTEC2101 Optimization Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class Give_Me_Some_Credit_Dataset_Class(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        for _, row in data_frame.iterrows():\n",
    "            features = row.iloc[:-1].values.astype(np.float32)\n",
    "            label = row.iloc[-1]\n",
    "            data.append(features)\n",
    "            targets.append(float(int(label)))\n",
    "        \n",
    "        data = torch.tensor(data)\n",
    "        targets = torch.tensor(targets)\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Give_Me_Some_Credit_train_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-train.csv', train=True, transform=normalize_tensor)\n",
    "Give_Me_Some_Credit_test_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-test.csv', train=False, transform=normalize_tensor)\n",
    "\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**\n",
    "\n",
    "Note: This dataset is best suited for binary classification. The training dataset contains 400000 objects. Each object is described by 2001 columns. The first column contains the label value, all other columns contain numerical features. The validation dataset contains 100000 objects. The structure is identical to the training dataset.\n",
    "\n",
    "Warning: The loading time for this dataset is too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class EpsilonDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "    \n",
    "    def process_line(self, line):\n",
    "        line = line.split(' ')\n",
    "        label, values = int(line[0]), line[1:]\n",
    "        value = torch.zeros(line[1:].size())\n",
    "        for item in values:\n",
    "            idx, val = item.split(':')\n",
    "            value[int(idx) - 1] = float(val)\n",
    "        return label, value\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Epsilon_train_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)\n",
    "Epsilon_test_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized.t', train=False, transform=None)\n",
    "\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Languages Dataset**\n",
    "\n",
    "The dataset is downloaded from here: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('Datasets/Language_dataset/names/*.txt'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "languages_dataset_category_lines = {}\n",
    "languages_dataset_all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('Datasets/Language_dataset/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages_dataset_all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    languages_dataset_category_lines[category] = lines\n",
    "\n",
    "n_categories = len(languages_dataset_all_categories)\n",
    "\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "Languages_train_dataset = LanguageDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Classes, Functions and Algorithms ##\n",
    "All common and helping functions for machine learning tasks are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#     Helping Functions    #\n",
    "############################\n",
    "# Random Seed Function\n",
    "# To ensure a same training result under the random process, you might need to set the random seed via this function.\n",
    "def set_random_seed(custom_random_seed):\n",
    "    torch.manual_seed(custom_random_seed)\n",
    "    random.seed(custom_random_seed)\n",
    "    np.random.seed(custom_random_seed)\n",
    "\n",
    "# Convert anything into a list if input is not a list\n",
    "def convert_to_list(input_list):\n",
    "    if not isinstance(input_list, list):\n",
    "        input_list = [input_list]\n",
    "    return input_list\n",
    "\n",
    "# Graph Plotting Functions\n",
    "def plot_cost_history(cost_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Cost\", title_name=\"Culminative Send Cost History\"):\n",
    "    cost_history_list = convert_to_list(cost_history_list)\n",
    "    for i, cost_history in enumerate(cost_history_list):\n",
    "        plt.plot(cost_history, label=f\"Cost History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(cost_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_culminative_send_cost_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_history(time_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Culminative Time Used\", title_name=\"Time History\"):\n",
    "    time_history_list = convert_to_list(time_history_list)\n",
    "    for i, time_history in enumerate(time_history_list):\n",
    "        plt.plot(time_history, label=f\"Time History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(time_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_time_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_adversary_history(adversary_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Adversaries\", title_name=\"Number of Adversaries History\"):\n",
    "    adversary_history_list = convert_to_list(adversary_history_list)\n",
    "    for i, adversary_history in enumerate(adversary_history_list):\n",
    "        plt.plot(adversary_history, label=f\"Adversary History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(adversary_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_adversary_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_straggler_history(straggler_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Stragglers\", title_name=\"Number of Stragglers History\"):\n",
    "    straggler_history_list = convert_to_list(straggler_history_list)\n",
    "    for i, straggler_history in enumerate(straggler_history_list):\n",
    "        plt.plot(straggler_history, label=f\"Straggler History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(straggler_history) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_straggler_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_history(train_loss_history_list=[], test_loss_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Loss\", title_name=\"Loss History\"):\n",
    "    train_loss_history_list = convert_to_list(train_loss_history_list)\n",
    "    test_loss_history_list = convert_to_list(test_loss_history_list)\n",
    "    for i, train_loss_history in enumerate(train_loss_history_list):\n",
    "        plt.plot(train_loss_history, label=f\"Train Loss History {i+1}\")\n",
    "    for i, test_loss_history in enumerate(test_loss_history_list):\n",
    "        plt.plot(test_loss_history, label=f\"Test Loss History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_loss_history_list) + len(test_loss_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_loss_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history(train_accuracy_history_list=[], test_accuracy_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Accuracy\", title_name=\"Accuracy History\"):\n",
    "    train_accuracy_history_list = convert_to_list(train_accuracy_history_list)\n",
    "    test_accuracy_history_list = convert_to_list(test_accuracy_history_list)\n",
    "    for i, train_accuracy_history in enumerate(train_accuracy_history_list):\n",
    "        plt.plot(train_accuracy_history, label=f\"Train Accuracy History {i+1}\")\n",
    "    for i, test_accuracy_history in enumerate(test_accuracy_history_list):\n",
    "        plt.plot(test_accuracy_history, label=f\"Test Accuracy History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_accuracy_history_list) + len(test_accuracy_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_accuracy_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_history(train_error_history_list=[], test_error_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Error\", title_name=\"Error History\"):\n",
    "    train_error_history_list = convert_to_list(train_error_history_list)\n",
    "    test_error_history_list = convert_to_list(test_error_history_list)\n",
    "    for i, train_error_history in enumerate(train_error_history_list):\n",
    "        plt.plot(train_error_history, label=f\"Train Error History {i+1}\")\n",
    "    for i, test_error_history in enumerate(test_error_history_list):\n",
    "        plt.plot(test_error_history, label=f\"Test Error History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_error_history_list) + len(test_error_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_error_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Accuracy and Error Rate Calculation\n",
    "def get_accuracy(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "\n",
    "def get_error(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions != labels).item() / len(predictions))\n",
    "\n",
    "def relative_rate_to_client_number(num_client, percentage = 1.00):\n",
    "    return round(num_client * percentage)\n",
    "\n",
    "############################\n",
    "#   Neural Network Model   #\n",
    "############################\n",
    "global Linear_Model_in_features\n",
    "global Linear_Model_out_features\n",
    "class Linear_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=Linear_Model_in_features, out_features=Linear_Model_out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "class Logistic_Regression_Model(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "class MNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class CIFAR10_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(128 * 8 * 8, 256)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class EMNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(7 * 7 * 64, 128)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(128, 26)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class RNN_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation_stack = torch.nn.Sequential(\n",
    "            torch.nn.RNN()\n",
    "        )\n",
    "\n",
    "############################\n",
    "#    Iterate Algorithm     #\n",
    "############################\n",
    "def evaluate_model_simple(model, dataloader, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "    return loss_average, accuracy_average, error_average\n",
    "\n",
    "def iterate_model_simple(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, test_dataloader=None, include_intial_history=False):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    if include_intial_history is True:\n",
    "        loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        loss_history.append(loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        error_history.append(error)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_average:.16f}, Train Accuracy: {accuracy_average:.16f}, Train Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "    if test_dataloader is not None:\n",
    "        return loss_history, accuracy_history, error_history, time_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################################################\n",
    "#  Dataset Preprocessing Functions Before Splitting For Clients  #\n",
    "##################################################################\n",
    "# Acknowledge from https://github.com/adap/flower/blob/main/baselines/fedprox/fedprox/dataset_preparation.py\n",
    "# Balance: Trims the dataset so each class contains as many elements as the class that contained the least elements.\n",
    "def dataset_balance_classes(trainset, seed=42):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    smallest = np.min(class_counts)\n",
    "    idxs = trainset.targets.argsort()\n",
    "    tmp = [Subset(trainset, idxs[: int(smallest)])]\n",
    "    tmp_targets = [trainset.targets[idxs[: int(smallest)]]]\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(Subset(trainset, idxs[int(count) : int(count + smallest)]))\n",
    "        tmp_targets.append(trainset.targets[idxs[int(count) : int(count + smallest)]])\n",
    "    unshuffled = ConcatDataset(tmp)\n",
    "    unshuffled_targets = torch.cat(tmp_targets)\n",
    "    shuffled_idxs = torch.randperm(\n",
    "        len(unshuffled), generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    shuffled = Subset(unshuffled, shuffled_idxs)\n",
    "    shuffled.targets = unshuffled_targets[shuffled_idxs]\n",
    "    return shuffled\n",
    "\n",
    "def dataset_sort_by_class(trainset: Dataset):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    idxs = trainset.targets.argsort()  # sort targets in ascending order\n",
    "\n",
    "    tmp = []  # create subset of smallest class\n",
    "    tmp_targets = []  # same for targets\n",
    "\n",
    "    start = 0\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(\n",
    "            Subset(trainset, idxs[start : int(count + start)])\n",
    "        )  # add rest of classes\n",
    "        tmp_targets.append(trainset.targets[idxs[start : int(count + start)]])\n",
    "        start += count\n",
    "    sorted_dataset = ConcatDataset(tmp)  # concat dataset\n",
    "    sorted_dataset.targets = torch.cat(tmp_targets)  # concat targets\n",
    "    return sorted_dataset\n",
    "\n",
    "# Implemention follow Li et al 2020: https://arxiv.org/abs/1812.06127 with default values set accordingly.\n",
    "global custom_power_law_num_labels_per_partition\n",
    "global custom_power_law_min_data_per_partition\n",
    "global custom_power_law_mean\n",
    "global custom_power_law_sigma\n",
    "custom_power_law_num_labels_per_partition = 2\n",
    "custom_power_law_min_data_per_partition = 10\n",
    "custom_power_law_mean = 0.0\n",
    "custom_power_law_sigma = 2.0\n",
    "def dataset_power_law_split(sorted_trainset, num_partitions):\n",
    "    # Custom Parameters\n",
    "    num_labels_per_partition = custom_power_law_num_labels_per_partition\n",
    "    min_data_per_partition = custom_power_law_min_data_per_partition\n",
    "    mean = custom_power_law_mean\n",
    "    sigma = custom_power_law_sigma\n",
    "\n",
    "    targets = sorted_trainset.targets\n",
    "    full_idx = list(range(len(targets)))\n",
    "\n",
    "    class_counts = np.bincount(sorted_trainset.targets)\n",
    "    labels_cs = np.cumsum(class_counts)\n",
    "    labels_cs = [0] + labels_cs[:-1].tolist()\n",
    "\n",
    "    partitions_idx: List[List[int]] = []\n",
    "    num_classes = len(np.bincount(targets))\n",
    "    hist = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    # assign min_data_per_partition\n",
    "    min_data_per_class = int(min_data_per_partition / num_labels_per_partition)\n",
    "    for u_id in range(num_partitions):\n",
    "        partitions_idx.append([])\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            # label for the u_id-th client\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            # record minimum data\n",
    "            indices = list(\n",
    "                full_idx[\n",
    "                    labels_cs[cls]\n",
    "                    + hist[cls] : labels_cs[cls]\n",
    "                    + hist[cls]\n",
    "                    + min_data_per_class\n",
    "                ]\n",
    "            )\n",
    "            partitions_idx[-1].extend(indices)\n",
    "            hist[cls] += min_data_per_class\n",
    "\n",
    "    # add remaining images following power-law\n",
    "    probs = np.random.lognormal(\n",
    "        mean,\n",
    "        sigma,\n",
    "        (num_classes, int(num_partitions / num_classes), num_labels_per_partition),\n",
    "    )\n",
    "    remaining_per_class = class_counts - hist\n",
    "    # obtain how many samples each partition should be assigned for each of the\n",
    "    # labels it contains\n",
    "    # pylint: disable=too-many-function-args\n",
    "    probs = (\n",
    "        remaining_per_class.reshape(-1, 1, 1)\n",
    "        * probs\n",
    "        / np.sum(probs, (1, 2), keepdims=True)\n",
    "    )\n",
    "\n",
    "    for u_id in range(num_partitions):\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            count = int(probs[cls, u_id // num_classes, cls_idx])\n",
    "\n",
    "            # add count of specific class to partition\n",
    "            indices = full_idx[\n",
    "                labels_cs[cls] + hist[cls] : labels_cs[cls] + hist[cls] + count\n",
    "            ]\n",
    "            partitions_idx[u_id].extend(indices)\n",
    "            hist[cls] += count\n",
    "\n",
    "    # construct subsets\n",
    "    partitions = [Subset(sorted_trainset, p) for p in partitions_idx]\n",
    "    return partitions\n",
    "\n",
    "# Distribute the training datasets to clients, remember it returns an array of datasets\n",
    "def split_datasets_for_clients_random(dataset, num_clients=1):\n",
    "    total_sample_size = len(dataset)\n",
    "    samples_per_clients = total_sample_size // num_clients\n",
    "    client_datasets = random_split(dataset, [min(i + samples_per_clients, total_sample_size) - i for i in range(0, total_sample_size, samples_per_clients)])\n",
    "    return client_datasets\n",
    "\n",
    "global custom_split_dataset_iid\n",
    "global custom_split_dataset_power_law\n",
    "global custom_split_dataset_balance\n",
    "global custom_split_dataset_seed\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "def split_datasets_for_clients_custom(dataset, num_clients=1):\n",
    "    # Custom Parameters\n",
    "    iid=custom_split_dataset_iid\n",
    "    power_law=custom_split_dataset_power_law\n",
    "    balance=custom_split_dataset_balance\n",
    "    seed=custom_split_dataset_seed\n",
    "\n",
    "    trainset = dataset\n",
    "    if balance:\n",
    "        trainset = dataset_balance_classes(trainset, seed)\n",
    "\n",
    "    partition_size = int(len(trainset) / num_clients)\n",
    "    lengths = [partition_size] * num_clients\n",
    "\n",
    "    if iid is True:\n",
    "        client_datasets = random_split(trainset, lengths, torch.Generator().manual_seed(seed))\n",
    "    else:\n",
    "        if power_law is True:\n",
    "            trainset_sorted = dataset_sort_by_class(trainset)\n",
    "            client_datasets = dataset_power_law_split(\n",
    "                trainset_sorted,\n",
    "                num_partitions=num_clients,\n",
    "            )\n",
    "        else:\n",
    "            shard_size = int(partition_size / 2)\n",
    "            idxs = trainset.targets.argsort()\n",
    "            sorted_data = Subset(trainset, idxs)\n",
    "            tmp = []\n",
    "            for idx in range(num_clients * 2):\n",
    "                tmp.append(\n",
    "                    Subset(\n",
    "                        sorted_data, np.arange(shard_size * idx, shard_size * (idx + 1))\n",
    "                    )\n",
    "                )\n",
    "            idxs_list = torch.randperm(\n",
    "                num_clients * 2, generator=torch.Generator().manual_seed(seed)\n",
    "            )\n",
    "            client_datasets = [\n",
    "                ConcatDataset((tmp[idxs_list[2 * i]], tmp[idxs_list[2 * i + 1]]))\n",
    "                for i in range(num_clients)\n",
    "            ]\n",
    "\n",
    "    return client_datasets\n",
    "\n",
    "############################\n",
    "#      Client Devices      #\n",
    "############################\n",
    "# Define a custom class for each client so they can update separately\n",
    "class ClientDevice:\n",
    "    def __init__(self, client_id, model, optimizer, dataset, batch_size, iterate_func, loss_func, accuracy_func=get_accuracy, error_func=get_error):\n",
    "        self.id = client_id\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = DeviceDataLoader(torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        self.iterate_func = iterate_func\n",
    "        self.loss_func = loss_func\n",
    "        self.accuracy_func = accuracy_func\n",
    "        self.error_func = error_func\n",
    "\n",
    "        # Framework Specificed Variables\n",
    "        self.straggler = False\n",
    "        self.client_controls = {}\n",
    "        self.full_batch_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False), device)\n",
    "\n",
    "        # Custom Variables\n",
    "        self.adversary = False\n",
    "        self.adversary_attack_func = None\n",
    "        self.adversary_attack_value = 0\n",
    "        self.adversary_attack_Scaffold_all = False\n",
    "\n",
    "    def load_weights(self, weights):\n",
    "        self.model.load_state_dict(weights)\n",
    "\n",
    "    def load_global_model(self, global_model):\n",
    "        for parameters, new_parameters in zip(self.model.parameters(), global_model.parameters()):\n",
    "            parameters.data = new_parameters.data.clone()\n",
    "\n",
    "    def copy_local_weights(self):\n",
    "        # This ensures dereferencing\n",
    "        model_weights = {}\n",
    "        for name, parameters in self.model.named_parameters():\n",
    "            model_weights[name] = parameters.data.clone()\n",
    "        return(model_weights)\n",
    "\n",
    "    def copy_local_model(self):\n",
    "        return self.model.state_dict().copy()\n",
    "\n",
    "    def get_client_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def save_local_history(self, num_epochs, loss_history, accuracy_history, error_history, time_history, value=train_start_time):\n",
    "        filename = \"{}_client_{}_with_local_epochs_{}_local_loss_accuracy_error_history_{}.npy\".format(current_dataset_name, self.id, num_epochs, value)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, loss_history=loss_history, accuracy_history=accuracy_history, error_history=error_history, time_history=time_history)\n",
    "\n",
    "    def train(self, num_epochs, show_message=True, plot_history=False):\n",
    "        if self.adversary is True:\n",
    "            if show_message:\n",
    "                print(f\"!-- Client {self.id} is a adversary and start iterations. ---!\")\n",
    "            self.adversary_attack_func(self.model, self.adversary_attack_value, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "        else:\n",
    "            if self.straggler is True:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is a straggler and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history = self.iterate_func(self.model, self.dataloader, random.randint(1, num_epochs), self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "            else:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is normal and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history = self.iterate_func(self.model, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "        if plot_history:\n",
    "            plot_time_history(time_history)\n",
    "            plot_loss_history(loss_history)\n",
    "            plot_accuracy_history(accuracy_history)\n",
    "            plot_error_history(error_history)\n",
    "        return self.copy_local_weights()\n",
    "\n",
    "    ## == Framework Specificed Functions == ##\n",
    "    def is_straggler(self):\n",
    "        return self.straggler\n",
    "\n",
    "    def get_local_client_controls(self):\n",
    "        return self.client_controls\n",
    "\n",
    "    def train_Scaffold(self, server_controls, num_epochs, Scaffold_update_controls_use_gradient, show_message=True, plot_history=False):\n",
    "        if self.adversary is True:\n",
    "            if show_message:\n",
    "                print(f\"!-- Client {self.id} is a adversary and start iterations. ---!\")\n",
    "            delta_weights, delta_client_controls = self.adversary_attack_func(self, self.adversary_attack_value, server_controls, self.dataloader, num_epochs, self.adversary_attack_Scaffold_all, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "        else:\n",
    "            if self.straggler is True:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is a straggler and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls = iterate_Scaffold_client(self, server_controls, self.dataloader, random.randint(1, num_epochs), self.optimizer, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "            else:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is normal and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls = iterate_Scaffold_client(self, server_controls, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "        if plot_history:\n",
    "            plot_time_history(time_history)\n",
    "            plot_loss_history(loss_history)\n",
    "            plot_accuracy_history(accuracy_history)\n",
    "            plot_error_history(error_history)\n",
    "        return delta_weights, delta_client_controls\n",
    "\n",
    "# Establish client devices\n",
    "def establish_client_devices(num_clients, model_list, optimizer_list, dataset_list, batch_size_list, iterate_func_list, loss_func_list, accuracy_func_list, error_func_list):\n",
    "    client_device = [None] * num_clients\n",
    "    for client_id in range(num_clients):\n",
    "        client_device[client_id] = ClientDevice(client_id, model_list[client_id], optimizer_list[client_id], dataset_list[client_id], batch_size_list[client_id], iterate_func_list[client_id], loss_func_list[client_id], accuracy_func_list[client_id], error_func_list[client_id])\n",
    "    return client_device\n",
    "\n",
    "############################\n",
    "#    Adversarial Attack    #\n",
    "############################\n",
    "def adversarial_attack_by_value(model, value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    for parameters in model.parameters():\n",
    "        parameters.data.fill_(value)\n",
    "    loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_random_range(model, value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "    loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_train_scaling(model, scale_value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_average:.16f}, Accuracy: {accuracy_average:.16f}, Error: {error_average:.16f}')\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data *= scale_value\n",
    "            if m.bias is not None:\n",
    "                m.bias.data *= scale_value\n",
    "    loss, accuracy,error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'After scaling weight with {scale_value}, Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_value_Scaffold_alternative(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    if all_bool is False:\n",
    "        client_controls = client.client_controls\n",
    "        client_controls_update = {}\n",
    "        old_model = copy.deepcopy(local_model)\n",
    "        temp = {}\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            parameters.data.fill_(value)\n",
    "            temp[name] = parameters.data.clone()\n",
    "        if Scaffold_update_controls_use_gradient is True:\n",
    "            old_model.zero_grad()\n",
    "            old_loss_grad_dict = {}\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name] = []\n",
    "            for batch in dataloader:\n",
    "                features, labels = batch\n",
    "                outputs = old_model(features)\n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                loss.detach()\n",
    "                for name, parameters in old_model.named_parameters():\n",
    "                    old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        else:\n",
    "            lr = client.optimizer.get_step_size()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        client.client_controls = client_controls_update\n",
    "    else:\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            parameters.data.fill_(value)\n",
    "            delta_weights[name] = parameters.data.clone()\n",
    "            delta_client_controls[name] = parameters.data.clone()\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "def adversarial_attack_by_value_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    optimizer = client.optimizer\n",
    "    old_model = copy.deepcopy(local_model)\n",
    "    client_controls = client.client_controls\n",
    "    lr = optimizer.get_step_size()\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = local_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step(server_controls, client_controls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    temp = {}\n",
    "    for name, parameters in local_model.named_parameters():\n",
    "        temp[name] = parameters.data.clone()\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        old_model.zero_grad()\n",
    "        old_loss_grad_dict = {}\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            old_loss_grad_dict[name] = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = old_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            loss.detach()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    else:\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "\n",
    "    for name in delta_client_controls.keys():\n",
    "        delta_weights[name] = torch.full_like(delta_weights[name], value)\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "def adversarial_attack_by_control_variable_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    optimizer = client.optimizer\n",
    "    old_model = copy.deepcopy(local_model)\n",
    "    client_controls = client.client_controls\n",
    "    lr = optimizer.get_step_size()\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = local_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step(server_controls, client_controls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    temp = {}\n",
    "    for name, parameters in local_model.named_parameters():\n",
    "        temp[name] = parameters.data.clone()\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        old_model.zero_grad()\n",
    "        old_loss_grad_dict = {}\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            old_loss_grad_dict[name] = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = old_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            loss.detach()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    else:\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "\n",
    "    for name in delta_client_controls.keys():\n",
    "        delta_client_controls[name] = torch.full_like(delta_client_controls[name], value)\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "def adversarial_attack_by_random_range_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    for m in local_model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    if all_bool is False:\n",
    "        client_controls = client.client_controls\n",
    "        client_controls_update = {}\n",
    "        old_model = copy.deepcopy(local_model)\n",
    "        temp = {}\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            temp[name] = parameters.data.clone()\n",
    "        if Scaffold_update_controls_use_gradient is True:\n",
    "            old_model.zero_grad()\n",
    "            old_loss_grad_dict = {}\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name] = []\n",
    "            for batch in dataloader:\n",
    "                features, labels = batch\n",
    "                outputs = old_model(features)\n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                loss.detach()\n",
    "                for name, parameters in old_model.named_parameters():\n",
    "                    old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        else:\n",
    "            lr = client.optimizer.get_step_size()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        client.client_controls = client_controls_update\n",
    "    else:\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            delta_weights[name] = parameters.data.clone()\n",
    "            delta_client_controls[name] = parameters.data.clone()\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "#########################################\n",
    "#     Federated Learning Algorithms     #\n",
    "#########################################\n",
    "def federated_averaging(global_model, client_weights_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for model in client_weights_total:\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name] += model[name] / random_sample_client_number\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data = global_step_size * aggregated_weights[name].data\n",
    "\n",
    "def federated_median(global_model, client_weights_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = []\n",
    "\n",
    "    for model in client_weights_total:\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name].append(model[name])\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data = global_step_size * torch.from_numpy(np.median(aggregated_weights[name], axis=0))\n",
    "\n",
    "def iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = [0]\n",
    "    time_history = [0]\n",
    "    adversary_history = [0]\n",
    "    straggler_history = [0]\n",
    "    \n",
    "    send_cost = 0.00\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    # Initialize server\n",
    "    num_clients = len(client_list)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        client_weights_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        num_adversary_in_round = 0\n",
    "        num_straggler_in_round = 0\n",
    "        for client in random_client_list:\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            client.load_global_model(global_model)\n",
    "            client_weights = client.train(num_epochs=local_epochs)\n",
    "            client_weights_total.append(client_weights)\n",
    "            send_cost += sum(value.numel() for value in client_weights.values())\n",
    "            if client.adversary is True:\n",
    "               num_adversary_in_round += 1\n",
    "            else:\n",
    "                if client.straggler is True:\n",
    "                   num_straggler_in_round += 1\n",
    "        aggregate_func(global_model, client_weights_total, num_clients, random_sample_client_number)\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "        adversary_history.append(num_adversary_in_round)\n",
    "        straggler_history.append(num_straggler_in_round)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(\"!-- Server Model Status --!\")\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "            print(f'Number of adversaries sampled: {num_adversary_in_round}, Number of stragglers sampled: {num_straggler_in_round}')\n",
    "\n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "#################################\n",
    "#  FedProx Framework Algorithm  #\n",
    "#################################\n",
    "def iterate_model_FedProx(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            proximal_term = 0.0\n",
    "            for w, w_t in zip(model.parameters(), FedProx_global_model.parameters()):\n",
    "                proximal_term += torch.square((w - w_t).norm(2))\n",
    "            loss = loss_func(outputs, labels) + (FedProx_mu / 2) * proximal_term\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################\n",
    "#  SCAFFOLD Framework Algorithm  #\n",
    "##################################\n",
    "# Inspired by https://github.com/ki-ljl/Scaffold-Federated-Learning/blob/main/ScaffoldOptimizer.py\n",
    "# c: server_controls, ci: client_controls\n",
    "class ScaffoldOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=required, weight_decay=None):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if weight_decay is not None and weight_decay < 0.0:\n",
    "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
    "        super(ScaffoldOptimizer, self).__init__(params, defaults)\n",
    "                \n",
    "    def step(self, server_controls, client_controls):\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            lr = group['lr']\n",
    "            for parameters, c, ci in zip(group['params'], server_controls.values(), client_controls.values()):\n",
    "                if parameters.grad is None:\n",
    "                    continue\n",
    "                parameters_derivative = parameters.grad.data - ci.data + c.data\n",
    "                if weight_decay is not None:\n",
    "                    parameters.data = weight_decay * parameters.data - lr * parameters_derivative.data\n",
    "                else:\n",
    "                    parameters.data = parameters.data - lr * parameters_derivative.data\n",
    "\n",
    "    def get_step_size(self):\n",
    "        return self.param_groups[0]['lr']\n",
    "\n",
    "def iterate_Scaffold_client(client, server_controls, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, Scaffold_update_controls_use_gradient=True, show_history=True):\n",
    "    local_model = client.model\n",
    "    old_model = copy.deepcopy(local_model)\n",
    "    client_controls = client.client_controls\n",
    "    lr = optimizer.get_step_size()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = local_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step(server_controls, client_controls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    temp = {}\n",
    "    for name, parameters in local_model.named_parameters():\n",
    "        temp[name] = parameters.data.clone()\n",
    "\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = old_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] += parameters.grad.data\n",
    "                delta_weights[name] = (temp[name] - parameters.data)\n",
    "                delta_client_controls[name] = (client_controls_update[name] - client_controls[name])\n",
    "            loss.detach()\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] /= len(dataloader)\n",
    "            delta_weights[name] = (temp[name] - parameters.data)\n",
    "            delta_client_controls[name] = (client_controls_update[name] - client_controls[name])\n",
    "    else:\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    print(client_controls_update)\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls\n",
    "\n",
    "def federated_averaging_Scaffold(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    aggregated_client_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = torch.zeros_like(parameters.data)\n",
    "        aggregated_client_controls[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for delta_weights, delta_client_controls in zip(delta_weights_total, delta_client_controls_total):\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name] += delta_weights[name] / random_sample_client_number\n",
    "            aggregated_client_controls[name] += delta_client_controls[name] / random_sample_client_number\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data += global_step_size * aggregated_weights[name].data\n",
    "        server_controls[name].data += (random_sample_client_number / num_clients) * aggregated_client_controls[name].data\n",
    "\n",
    "def federated_median_Scaffold(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    aggregated_client_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = []\n",
    "        aggregated_client_controls[name] = []\n",
    "\n",
    "    for delta_weights, delta_client_controls in zip(delta_weights_total, delta_client_controls_total):\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name].append(delta_weights[name])\n",
    "            aggregated_client_controls[name].append(delta_client_controls[name])\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data += global_step_size * torch.from_numpy(np.median(aggregated_weights[name], axis=0))\n",
    "        server_controls[name].data += (random_sample_client_number / num_clients) * torch.from_numpy(np.median(aggregated_client_controls[name], axis=0))\n",
    "\n",
    "def iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient=False, aggregate_func=federated_averaging_Scaffold, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = [0]\n",
    "    time_history = [0]\n",
    "    adversary_history = [0]\n",
    "    straggler_history = [0]\n",
    "    \n",
    "    send_cost = 0.00\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    # Initialize server and client controls\n",
    "    num_clients = len(client_list)\n",
    "    server_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        server_controls[name] = torch.zeros_like(parameters.data)\n",
    "    for client in client_list:\n",
    "        for name, parameters in client.model.named_parameters():\n",
    "            client.client_controls[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        delta_weights_total = []\n",
    "        delta_client_controls_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        num_adversary_in_round = 0\n",
    "        num_straggler_in_round = 0\n",
    "        for client in random_client_list:\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            send_cost += sum(value.numel() for value in server_controls.values())\n",
    "            client.load_global_model(global_model)\n",
    "            delta_weights, delta_client_controls = client.train_Scaffold(server_controls, local_epochs, Scaffold_update_controls_use_gradient)\n",
    "            delta_weights_total.append(delta_weights)\n",
    "            delta_client_controls_total.append(delta_client_controls)\n",
    "            print(\"=== delta_weights ===\")\n",
    "            print(delta_weights)\n",
    "            print(\"=== delta_client_controls ===\")\n",
    "            print(delta_client_controls)\n",
    "            print(\"=== end track ===\")\n",
    "            send_cost += sum(value.numel() for value in delta_weights.values())\n",
    "            send_cost += sum(value.numel() for value in delta_client_controls.values())\n",
    "            if client.adversary is True:\n",
    "               num_adversary_in_round += 1\n",
    "            else:\n",
    "                if client.straggler is True:\n",
    "                   num_straggler_in_round += 1\n",
    "        aggregate_func(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size)\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "        adversary_history.append(num_adversary_in_round)\n",
    "        straggler_history.append(num_straggler_in_round)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(\"!-- Server Model Status --!\")\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "            print(f'Number of adversaries sampled: {num_adversary_in_round}, Number of stragglers sampled: {num_straggler_in_round}')\n",
    "\n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#    Training Algorithm    #\n",
    "############################\n",
    "global save_file_extra_information\n",
    "save_file_extra_information = \"None.\"\n",
    "def train_neural_network_model(model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"Centralized\"):\n",
    "    if test_dataloader is not None:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history, test_loss_history, test_accuracy_history, test_error_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, test_dataloader, True)\n",
    "    else:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, True)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"FederatedLearning\"):\n",
    "    cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, adversary_history=adversary_history, straggler_history=straggler_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "        plot_adversary_history([adversary_history])\n",
    "        plot_straggler_history([straggler_history])\n",
    "    \n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func=federated_averaging_Scaffold, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"Scaffold\"):\n",
    "    cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, adversary_history=adversary_history, straggler_history=straggler_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "        plot_adversary_history([adversary_history])\n",
    "        plot_straggler_history([straggler_history])\n",
    "    \n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#   Experiment Functions   #\n",
    "############################\n",
    "def experiment_neural_network_model(train_dataset, test_dataset, modelClass, optimizerClass, train_func, epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    epochs_list = convert_to_list(epochs_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'number of epochs is {epochs_list[min(n, len(epochs_list) - 1)]}')\n",
    "        num_epochs = epochs_list[min(n, len(epochs_list) - 1)]\n",
    "        print(f'learning rate is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        optimizer = optimizerClass(global_model.parameters(), learning_rate)\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_Centralized_E_{num_epochs}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        [should be Centralized Training]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "\n",
    "        num_epochs_list = {epochs_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        num_epochs = {num_epochs}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        \"\"\"\n",
    "\n",
    "        time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_func(global_model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "\n",
    "def experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(adversary):\n",
    "            client_list[i].adversary = True\n",
    "            client_list[i].adversary_attack_func = adversary_attack_func\n",
    "            client_list[i].adversary_attack_value = adversary_attack_value\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be FedAvg]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)\n",
    "\n",
    "def experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "    mu_list = convert_to_list(mu_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "\n",
    "    global FedProx_global_model\n",
    "    global FedProx_mu\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate list is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size list is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'straggler is {straggler_list[min(n, len(straggler_list) - 1)]}')\n",
    "        straggler = straggler_list[min(n, len(straggler_list) - 1)]\n",
    "        print(f'mu is {mu_list[min(n, len(mu_list) - 1)]}')\n",
    "        FedProx_mu = mu_list[min(n, len(mu_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "        FedProx_global_model = global_model\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        for i in range(adversary):\n",
    "            if client_list[i].straggler is True:\n",
    "                client_list[i+straggler].adversary = True\n",
    "                client_list[i+straggler].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i+straggler].adversary_attack_value = adversary_attack_value\n",
    "            else:\n",
    "                client_list[i].adversary = True\n",
    "                client_list[i].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i].adversary_attack_value = adversary_attack_value\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be FedProx]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        straggler_list = {straggler_list}\n",
    "        mu_list = {mu_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        straggler = {straggler}\n",
    "        mu = {FedProx_mu}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)\n",
    "\n",
    "def experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list = False, straggler_list = [0], adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, adversary_attack_Scaffold_all_list = False, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    global_step_size_list = convert_to_list(global_step_size_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    Scaffold_update_controls_use_gradient_list = convert_to_list(Scaffold_update_controls_use_gradient_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "    adversary_attack_Scaffold_all_list = convert_to_list(adversary_attack_Scaffold_all_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate list is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'global step size is {global_step_size_list[min(n, len(global_step_size_list) - 1)]}')\n",
    "        global_step_size = global_step_size_list[min(n, len(global_step_size_list) - 1)]\n",
    "        print(f'batch size list is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'use gradient to update control variable is {Scaffold_update_controls_use_gradient_list[min(n, len(Scaffold_update_controls_use_gradient_list) - 1)]}')\n",
    "        Scaffold_update_controls_use_gradient = Scaffold_update_controls_use_gradient_list[min(n, len(Scaffold_update_controls_use_gradient_list) - 1)]\n",
    "        print(f'straggler is {straggler_list[min(n, len(straggler_list) - 1)]}')\n",
    "        straggler = straggler_list[min(n, len(straggler_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        print(f'adversary attack include control variables is {adversary_attack_Scaffold_all_list[min(n, len(adversary_attack_Scaffold_all_list) - 1)]}')\n",
    "        adversary_attack_Scaffold_all = adversary_attack_Scaffold_all_list[min(n, len(adversary_attack_Scaffold_all_list) - 1)]\n",
    "\n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        for i in range(adversary):\n",
    "            if client_list[i].straggler is True:\n",
    "                client_list[i+straggler].adversary = True\n",
    "                client_list[i+straggler].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i+straggler].adversary_attack_value = adversary_attack_value\n",
    "                client_list[i+straggler].adversary_attack_Scaffold_all = adversary_attack_Scaffold_all\n",
    "            else:\n",
    "                client_list[i].adversary = True\n",
    "                client_list[i].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i].adversary_attack_value = adversary_attack_value\n",
    "                client_list[i].adversary_attack_Scaffold_all = adversary_attack_Scaffold_all\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be Scaffold]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        global_step_size_list = {global_step_size_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        Scaffold_update_controls_use_gradient_list = {Scaffold_update_controls_use_gradient_list}\n",
    "        straggler_list = {straggler_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "        adversary_attack_Scaffold_all_list = {adversary_attack_Scaffold_all_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        global_step_size = {global_step_size}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        Scaffold_update_controls_use_gradient = {Scaffold_update_controls_use_gradient}\n",
    "        straggler = {straggler}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        adversary_attack_Scaffold_all = {adversary_attack_Scaffold_all}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Experiment ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1 Choosing Dataset ###\n",
    "\n",
    "In this section, execute a cell only to choose a dataset you want do experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 784\n",
    "model_type_preset = MNIST_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 1024\n",
    "model_type_preset = CIFAR10_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = EMNIST_train_dataset\n",
    "test_dataset = EMNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"EMNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 26\n",
    "input_dim = 784\n",
    "model_type_preset = EMNIST_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "Linear_Model_in_features = 7\n",
    "Linear_Model_out_features = 1\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**########################### MAIN REDO ################################################**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [0]\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [0.5]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 10\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [0]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversary Redo (MNIST Only is fine)\n",
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 10\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [1]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 1000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 Neural Network Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 100\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 100\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 FedAvg Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 FedProx Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Straggler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0, 0, 0, 1.0, 1.0, 1.0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0, 0, 0, 1.0, 1.0, 1.0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedProx Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100, 10, 100]\n",
    "random_sample_client_number_list = [10, 20, 10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [1, 20, 1, 20]\n",
    "mu_list = [0.0, 0.0, 1.0, 1.0]\n",
    "adversary_list = [1, 20, 1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100, 10, 100]\n",
    "random_sample_client_number_list = [10, 20, 10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [1, 20, 1, 20]\n",
    "mu_list = [0.0, 0.0, 1.0, 1.0]\n",
    "adversary_list = [1, 20, 1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5 Scaffold Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 10\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [1]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 1000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0, 50, 90]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, True, False, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, True, False, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.6 Federated Median Learning Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaffold Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [1, 20]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [1, 20]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.0 Loading Data ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear and Initialize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cost_history_total = []\n",
    "data_time_history_total = []\n",
    "data_adversary_history_total = []\n",
    "data_straggler_history_total = []\n",
    "data_train_loss_history_total = []\n",
    "data_train_accuracy_history_total = []\n",
    "data_train_error_history_total = []\n",
    "data_test_loss_history_total = []\n",
    "data_test_accuracy_history_total = []\n",
    "data_test_error_history_total = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filename_load path manually here!!\n",
    "filename_load_list = [\"MNIST_Scaffold_GE_50_LE_3_C_50_RC_25_lr_0.03_B_128_2024-04-07 16.25.58_1.npy\",\n",
    "                      \"MNIST_Scaffold_GE_50_LE_3_C_50_RC_25_lr_0.03_B_128_2024-04-07 16.25.58_2.npy\"]\n",
    "data_append_load = True\n",
    "load_consider_cost_bool = True\n",
    "load_consider_time_bool = True\n",
    "load_consider_adversary_bool = True\n",
    "load_consider_straggler_bool = True\n",
    "\n",
    "for filename_load in filename_load_list:\n",
    "    print(\"============================================\")\n",
    "    print(\"*** Loading file...                     ***\")\n",
    "    print(\"============================================\")\n",
    "    try:\n",
    "        # Load the file\n",
    "        load_result = np.load(filename_load)\n",
    "        print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "        # Load the attributes from the file\n",
    "        if load_consider_cost_bool is True:\n",
    "            data_cost_history = load_result['cost_history']\n",
    "        if load_consider_time_bool is True:\n",
    "            data_time_history = load_result['time_history']\n",
    "        if load_consider_adversary_bool is True:\n",
    "            data_adversary_history = load_result['adversary_history']\n",
    "        if load_consider_adversary_bool is True:\n",
    "            data_straggler_history = load_result['straggler_history']\n",
    "        data_train_loss_history = load_result['train_loss_history']\n",
    "        data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "        data_train_error_history = load_result['train_error_history']\n",
    "        data_test_loss_history = load_result['test_loss_history']\n",
    "        data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "        data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "        print(\"=======Content of the File=======\")\n",
    "        print(load_result.files)\n",
    "\n",
    "        print(\"=======VISUALIZATION RESULT=======\")\n",
    "        if load_consider_cost_bool is True:\n",
    "            plot_cost_history([data_cost_history], save=False)\n",
    "        if load_consider_time_bool is True:\n",
    "            plot_time_history([data_time_history], save=False)\n",
    "        if load_consider_adversary_bool is True:\n",
    "            plot_adversary_history([data_adversary_history], save=False)\n",
    "        if load_consider_straggler_bool is True:\n",
    "            plot_straggler_history([data_straggler_history], save=False)\n",
    "        plot_loss_history([data_train_loss_history], [data_test_loss_history], save=False)\n",
    "        plot_accuracy_history([data_train_accuracy_history], [data_test_accuracy_history], save=False)\n",
    "        plot_error_history([data_train_error_history], [data_test_error_history], save=False)\n",
    "\n",
    "        print(\"=======STATUS RESULT=======\")\n",
    "        if load_consider_cost_bool is True:\n",
    "            print(\"Cost History: \", data_cost_history)\n",
    "        if load_consider_time_bool is True:\n",
    "            print(\"Time History: \", data_time_history)\n",
    "        if load_consider_adversary_bool is True:\n",
    "            print(\"Adversary History: \", data_adversary_history)\n",
    "        if load_consider_straggler_bool is True:\n",
    "            print(\"Straggler History: \", data_straggler_history)\n",
    "\n",
    "        print(\"=======TRAIN RESULT=======\")\n",
    "        print(\"Train Loss History: \", data_train_loss_history)\n",
    "        print(\"Train Accuracy History: \", data_train_accuracy_history)\n",
    "        print(\"Train Error History: \", data_train_error_history)\n",
    "\n",
    "        print(\"=======TEST RESULT=======\")\n",
    "        print(\"Test Loss History: \", data_test_loss_history)\n",
    "        print(\"Test Accuracy History: \", data_test_accuracy_history)\n",
    "        print(\"Test Error History: \", data_test_error_history)\n",
    "\n",
    "        # Append the data\n",
    "        if data_append_load:\n",
    "            if load_consider_cost_bool is True:\n",
    "                data_cost_history_total.append(data_cost_history)\n",
    "            if load_consider_time_bool is True:\n",
    "                data_time_history_total.append(data_time_history)\n",
    "            if load_consider_adversary_bool is True:\n",
    "                data_adversary_history_total.append(data_adversary_history)\n",
    "            if load_consider_straggler_bool is True:\n",
    "                data_straggler_history_total.append(data_straggler_history)\n",
    "            data_train_loss_history_total.append(data_train_loss_history)\n",
    "            data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "            data_train_error_history_total.append(data_train_error_history)\n",
    "            data_test_loss_history_total.append(data_test_loss_history)\n",
    "            data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "            data_test_error_history_total.append(data_test_error_history)\n",
    "    except (FileNotFoundError, IOError):\n",
    "        print(\"Failed to load the file: \", filename_load)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.1 Data Visualization ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize All Data Directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_history(data_cost_history_total, save=False)\n",
    "plot_time_history(data_time_history_total, save=False)\n",
    "plot_adversary_history(data_adversary_history_total, save=False)\n",
    "plot_straggler_history(data_straggler_history_total, save=False)\n",
    "plot_loss_history(data_train_loss_history_total, data_test_loss_history_total, save=False)\n",
    "plot_accuracy_history(data_train_accuracy_history_total, data_test_accuracy_history_total, save=False)\n",
    "plot_error_history(data_train_error_history_total, data_test_error_history_total, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment Graph in Centralized Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_list = [1, 2, 3, 4, 5, 10]\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = True\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "        plt.plot(plot_train_loss_history, label=f\"Train Loss History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "        plt.plot(plot_test_loss_history, label=f\"Test Loss History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_loss_history_centralized_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "        plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "        plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_accuracy_history_centralized_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "        plt.plot(plot_train_error_history, label=f\"Train Error History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "        plt.plot(plot_test_error_history, label=f\"Test Error History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Error\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_error_history_centralized_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment Graph between different parameters in Federated Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters_list = [0, 1]\n",
    "plot_title_strings = \"different stragglers\"\n",
    "plot_legend_strings = \"stragglers\"\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = False\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "        plt.plot(plot_train_loss_history, label=f\"Train Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "        plt.plot(plot_test_loss_history, label=f\"Test Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_loss_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "        plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "        plt.plot(plot_test_accuracy_history, label=f\"Test Aacuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_accuracy_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "        plt.plot(plot_train_error_history, label=f\"Train Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "        plt.plot(plot_test_error_history, label=f\"Test Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Error\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_error_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_time_history = convert_to_list(data_time_history_total)\n",
    "for i, plot_time_history in enumerate(plot_different_parameter_time_history):\n",
    "    plt.plot(plot_time_history, label=f\"Time History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Culminative Time Used\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Culminative Time Used\")\n",
    "plt.title(\"Time History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_time_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_cost_history = convert_to_list(data_cost_history_total)\n",
    "for i, plot_cost_history in enumerate(plot_different_parameter_cost_history):\n",
    "    plt.plot(plot_cost_history, label=f\"Time History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Cost\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Cost\")\n",
    "plt.title(\"Culminative Send Cost History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_cost_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_adversary_history = convert_to_list(data_adversary_history_total)\n",
    "for i, plot_adversary_history in enumerate(plot_different_parameter_adversary_history):\n",
    "    plt.plot(plot_adversary_history, label=f\"Adversary History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Adversaries\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Adversaries\")\n",
    "plt.title(\"Number of Adversary History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_adversary_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_straggler_history = convert_to_list(data_adversary_history_total)\n",
    "for i, plot_straggler_history in enumerate(plot_different_parameter_straggler_history):\n",
    "    plt.plot(plot_straggler_history, label=f\"Straggler History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Stragglers\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Stragglers\")\n",
    "plt.title(\"Number of Stragglers History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_straggler_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.2 Analysing ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance = statistics.variance(data_cost_history)\n",
    "    time_variance = statistics.variance(data_time_history)\n",
    "    train_loss_variance = statistics.variance(data_train_loss_history)\n",
    "    train_accuracy_variance = statistics.variance(data_train_accuracy_history)\n",
    "    train_error_variance = statistics.variance(data_train_error_history)\n",
    "    test_loss_variance = statistics.variance(data_test_loss_history)\n",
    "    test_accuracy_variance = statistics.variance(data_test_accuracy_history)\n",
    "    test_error_variance = statistics.variance(data_test_error_history)\n",
    "    print(\"=======VARIANCE RESULT=======\")\n",
    "    print(\"Cost Variance: \", cost_variance)\n",
    "    print(\"Time Variance: \", time_variance)\n",
    "    print(\"Train Loss Variance: \", train_loss_variance)\n",
    "    print(\"Train Accuracy Variance: \", train_accuracy_variance)\n",
    "    print(\"Train Error Variance: \", train_error_variance)\n",
    "    print(\"Test Loss Variance: \", test_loss_variance)\n",
    "    print(\"Test Accuracy Variance: \", test_accuracy_variance)\n",
    "    print(\"Test Error Variance: \", test_error_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_variance_subset_min = 0\n",
    "analysis_variance_subset_max = len(data_cost_history) // 2\n",
    "\n",
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    time_variance_subset = statistics.variance(data_time_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    print(f'=======VARIANCE RESULT IN SUBSET BETWEEN {analysis_variance_subset_min} and {analysis_variance_subset_max}=======')\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[:len(data_cost_history) // 2])\n",
    "    time_variance_subset = statistics.variance(data_time_history[:len(data_time_history) // 2])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[:len(data_train_loss_history) // 2])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[:len(data_train_accuracy_history) // 2])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[:len(data_train_error_history) // 2])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[:len(data_test_loss_history) // 2])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[:len(data_test_accuracy_history) // 2])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[:len(data_test_error_history) // 2])\n",
    "    print(\"=======VARIANCE FIRST SUBSET RESULT=======\")\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[len(data_cost_history) // 2:])\n",
    "    time_variance_subset = statistics.variance(data_time_history[len(data_time_history) // 2:])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[len(data_train_loss_history) // 2:])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[len(data_train_accuracy_history) // 2:])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[len(data_train_error_history) // 2:])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[len(data_test_loss_history) // 2:])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[len(data_test_accuracy_history) // 2:])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[len(data_test_error_history) // 2:])\n",
    "    print(\"=======VARIANCE LAST SUBSET RESULT=======\")\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_average_subset_min = 0\n",
    "analysis_average_subset_max = len(data_cost_history) // 2\n",
    "\n",
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_average_subset = statistics.mean(data_cost_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    time_average_subset = statistics.mean(data_time_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_loss_average_subset = statistics.mean(data_train_loss_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_accuracy_average_subset = statistics.mean(data_train_accuracy_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_error_average_subset = statistics.mean(data_train_error_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_loss_average_subset = statistics.mean(data_test_loss_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_accuracy_average_subset = statistics.mean(data_test_accuracy_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_error_average_subset = statistics.mean(data_test_error_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    print(f'=======AVERAGE RESULT IN SUBSET BETWEEN {analysis_average_subset_min} and {analysis_average_subset_max}=======')\n",
    "    print(\"Cost Average in Subset: \", cost_average_subset)\n",
    "    print(\"Time Average in Subset: \", time_average_subset)\n",
    "    print(\"Train Loss Average in Subset: \", train_loss_average_subset)\n",
    "    print(\"Train Accuracy Average in Subset: \", train_accuracy_average_subset)\n",
    "    print(\"Train Error Average in Subset: \", train_error_average_subset)\n",
    "    print(\"Test Loss Average in Subset: \", test_loss_average_subset)\n",
    "    print(\"Test Accuracy Average in Subset: \", test_accuracy_average_subset)\n",
    "    print(\"Test Error Average in Subset: \", test_error_average_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Image Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"Test.png\"\n",
    "test_model_type = MNIST_CNN_Model\n",
    "test_model_path = \"MNIST_FedAvg_with_global_epochs_100_local_epochs_3_num_clients_1_batch_size_128_2024-03-01 16.14.36_model_state_dict.pth\"\n",
    "test_image_resize = 28\n",
    "test_image_togrey = True\n",
    "\n",
    "test_global_model = test_model_type()\n",
    "test_global_model.load_state_dict(torch.load(test_model_path, map_location=device))\n",
    "\n",
    "if test_image_togrey is True:\n",
    "    test_image = 1.0 - cv2.cvtColor(cv2.resize(load_image(test_image_path), (test_image_resize, test_image_resize)), cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    test_image = cv2.resize(load_image(test_image_path), (test_image_resize, test_image_resize))\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "test_image_torch = torch.Tensor(test_image[np.newaxis, np.newaxis])\n",
    "test_predicted_label_array = test_global_model(test_image_torch).detach().numpy()[0, ...]\n",
    "print('The chances for predicted labels are: ', test_predicted_label_array)\n",
    "\n",
    "test_predicted_label = np.argmax(test_predicted_label_array)\n",
    "\n",
    "print('The predicted label is: ', test_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
